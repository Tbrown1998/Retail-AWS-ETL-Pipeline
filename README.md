# Retail AWS ETL Pipeline
A Production-Grade, Serverless Data Ingestion & Transformation Framework for Retail Transaction Files


![alt text](<imgs/Data flow image.png>)

This repository contains a fully automated, fault-tolerant, and highly extensible **retail data ingestion pipeline** built on **AWS serverless technologies** (S3, Lambda, Glue, SNS). It handles semi-structured CSV retail transaction files, validates them, enforces business rules, transforms them using PySpark, and stores clean, query-ready datasets in a data lake architecture.

The pipeline enforces industry best practices:
- event-driven ingestion
- multi-layer S3 data lake organization (raw, validated, processed, gold, rejected, archive)
- header-flexible parsing with synonym mapping
- hardened multi-format timestamp parsing
- business data-quality enforcement
- atomic processing (no partial partitions)
- detailed rejection logging (JSON + CSV)
- observability via SNS + CloudWatch
- archival with traceable naming

## Folder structure (Repository)
```
RETAIL-AWS-ETL-PIPELINE/
â”‚
â”œâ”€â”€ .git/
â”‚
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture.md
â”‚   â”œâ”€â”€ athena_queries.md
â”‚   â”œâ”€â”€ dataflow.md
â”‚   â”œâ”€â”€ file_movement.md
â”‚   â”œâ”€â”€ glue_crawlers.md
â”‚   â”œâ”€â”€ glue_etl.md
â”‚   â”œâ”€â”€ gold_job.md
|   â”œâ”€â”€ iam_roles_permissions.md
â”‚   â”œâ”€â”€ job_parameters.md
â”‚   â”œâ”€â”€ lambda_validation.md
â”‚   â”œâ”€â”€ monitoring.md
â”‚   â”œâ”€â”€ rejects.md
â”‚   â”œâ”€â”€ s3_layout.md
â”‚   â”œâ”€â”€ schema_mapping.md
â”‚   â”œâ”€â”€ scripts.md
â”‚   â”œâ”€â”€ timestamp_parsing.md
â”‚   â”œâ”€â”€ troubleshooting.md
â”‚   â”œâ”€â”€ validation.md
â”‚
â”œâ”€â”€ imgs/
â”‚   â”œâ”€â”€ (architecture and data flow images)
â”‚
â”œâ”€â”€ sample_csv_files/
â”‚   â”œâ”€â”€ sales_2024-10-16.csv
â”‚   â”œâ”€â”€ sales_2024-12-07.csv
â”‚   â”œâ”€â”€ sales_2025-06-12.csv
â”‚   â”œâ”€â”€ sales_2025-09-03.csv
â”‚   â”œâ”€â”€ sales_2025-10-18.csv
â”‚
â””â”€â”€ scripts/
    â”œâ”€â”€ glue_job_raw_to_processed.py
    â”œâ”€â”€ incremental_auto_compaction.py
    â””â”€â”€ lambda_validator.py

```

## Key Capabilities
- Flexible header-based mapping (synonyms & variations supported)
- Automatic delimiter detection (, ; | \t)
- Hardened multi-format timestamp parsing (regex-gated)
- Strict data quality with structured + human-readable reject logs
- Zero partial ingestion â€” atomic writes with rollback
- Partitioned Parquet output optimized for Athena / Glue Catalog
- GOLD layer (analytics-ready) compaction and deduplication job
- SNS-based notifications for summary and system failures
- Archival naming: `<filename>_<YYYYMMDDTHHMMSS>_<ingest_run_id>`

## High-Level Architecture
```
raw/  â†’  Lambda Validator
         â†’ validated/ (pass)
         â†’ rejected/system/ (fail)

validated/ â†’ Glue ETL (bronzeâ†’silver processed/)
             â†’ processed/ (parquet partitioned by date)
             â†’ rejected/data_quality/ (row-level rejects)
             â†’ rejected/system/ (glue errors)
             â†’ archive/validated/<filename>_<ts>_<ingest_run_id>

processed/ â†’ GOLD compaction (Glue job 2)
             â†’ gold/fact_sales/date=YYYY-MM-DD/
             â†’ optional Glue crawler -> Glue Catalog / Athena
```


## Gold layer summary
The GOLD layer contains curated, analytics-ready tables (facts) created from processed data. A separate Glue job (`incremental_auto_compaction.py`) compacts daily partitions from `processed/` into `gold/fact_sales/` performing deduplication, basic data normalization, row hashing, and audit metrics. The gold job writes per-partition audit JSON files and optionally triggers a Glue crawler to update the Glue Data Catalog.

## How to use this repo
1. Review `docs/` for detailed architecture, flow, and operational steps.
2. Place production-ready scripts in `scripts/` (Glue jobs and Lambda).
3. Deploy Lambda to validate files dropped to `raw/`.
4. Deploy Glue job for raw->processed (bronze/silver).
5. Deploy the gold compaction Glue job to run periodically or on-demand.
6. Configure Glue crawlers and Athena for querying the processed and gold layers.

---

## ğŸ” IAM Roles Overview

This pipeline uses dedicated IAM roles to ensure secure, least-privilege access across all AWS services involved.

### **LambdaValidationRole**
Handles RAW â†’ VALIDATED/REJECTED:
- Read from `raw/`
- Write to `validated/` and `rejected/system/`
- Delete processed RAW files
- Publish SNS alerts
- Write CloudWatch logs

### **GlueETLRole**
Used by the Glue ETL job (VALIDATED â†’ PROCESSED):
- Read from `validated/`
- Write to `processed/`, `rejected/data_quality/`, and `archive/`
- Delete validated files after success
- Publish SNS notifications  
- Optionally start Glue crawlers

### **GlueGoldRole**
Used by the Gold Compaction job (PROCESSED â†’ GOLD):
- Read processed partitions
- Write compacted gold data and audit metrics
- Overwrite existing partitions safely
- Start Glue crawler (optional)
- Write logs to CloudWatch

### **GlueCrawlerRole**
Used by Glue Crawlers:
- Read `processed/` and `gold/` folders
- Update Glue Data Catalog tables & partitions
- Emit logs to CloudWatch

### **Monitoring Roles**
All compute services (Lambda + Glue) have:
- CloudWatch logging permissions  
- SNS publish permissions for alerts

### **Bucket Policy (Recommended)**
- Block public access  
- Enforce SSL  
- Enforce encryption  
- Allow only pipeline IAM roles to write  

These roles together enforce a secure, production-grade, least-privilege architecture where every service can interact safely while keeping data protected and traceable.

```
flowchart LR

    %% STYLE
    classDef role fill=#f9f9f9,stroke=#555,stroke-width=1px,color=#000,border-radius=6px;
    classDef service fill=#eef7ff,stroke=#4a90e2,stroke-width=1px,border-radius=6px;
    classDef bucket fill=#fef7e0,stroke=#e2a93b,stroke-width=1px,border-radius=6px;
    classDef monitor fill=#fdeaea,stroke=#e26a6a,stroke-width=1px,border-radius=6px;

    %% SERVICES
    RAW((S3 RAW)):::bucket
    VALIDATED((S3 VALIDATED)):::bucket
    PROCESSED((S3 PROCESSED)):::bucket
    GOLD((S3 GOLD)):::bucket

    SNS((SNS Topics)):::monitor
    CW((CloudWatch Logs)):::monitor
    CATALOG((Glue Data Catalog)):::service

    %% ROLES
    LAMBDA_ROLE([LambdaValidationRole]):::role
    GLUE_ETL_ROLE([GlueETLRole]):::role
    GLUE_GOLD_ROLE([GlueGoldRole]):::role
    CRAWLER_ROLE([GlueCrawlerRole]):::role

    %% LAMBDA VALIDATOR
    RAW -->|read| LAMBDA_ROLE
    LAMBDA_ROLE -->|write| VALIDATED
    LAMBDA_ROLE -->|write rejects| RAW
    LAMBDA_ROLE -->|publish| SNS
    LAMBDA_ROLE -->|logs| CW

    %% GLUE ETL ROLE
    VALIDATED -->|read| GLUE_ETL_ROLE
    GLUE_ETL_ROLE -->|write processed| PROCESSED
    GLUE_ETL_ROLE -->|write rejects| RAW
    GLUE_ETL_ROLE -->|archive validated| VALIDATED
    GLUE_ETL_ROLE -->|publish| SNS
    GLUE_ETL_ROLE -->|logs| CW

    %% GOLD ROLE
    PROCESSED -->|read| GLUE_GOLD_ROLE
    GLUE_GOLD_ROLE -->|write gold| GOLD
    GLUE_GOLD_ROLE -->|audit metrics| RAW
    GLUE_GOLD_ROLE -->|start crawler| CRAWLER_ROLE
    GLUE_GOLD_ROLE -->|logs| CW

    %% CRAWLER ROLE
    GOLD -->|read| CRAWLER_ROLE
    PROCESSED -->|read| CRAWLER_ROLE
    CRAWLER_ROLE -->|update tables| CATALOG
    CRAWLER_ROLE -->|logs| CW


```

---

# ğŸ“« Contact

## Oluwatosin Amosu Bolaji 
- Data Engineer 
- Buiness Intelligence Analyst
- ETL Developer

#### ğŸš€ **Always learning. Always building. Data-driven to the core.**  

### ğŸ“« **Letâ€™s connect!**  
- ğŸ“© oluwabolaji60@gmail.com
- ğŸ”— : [LinkedIn](https://www.linkedin.com/in/oluwatosin-amosu-722b88141)
- ğŸŒ : [My Portfolio](https://www.datascienceportfol.io/oluwabolaji60) 
- ğ• : [Twitter/X](https://x.com/thee_oluwatosin?s=21&t=EqoeQVdQd038wlSUzAtQzw)
- ğŸ”— : [Medium](https://medium.com/@oluwabolaji60)
- ğŸ”— : [View my Repositories](https://github.com/Tbrown1998?tab=repositories)
